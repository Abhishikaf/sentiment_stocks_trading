{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86604745-0606-4984-87a3-0645acef273f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vaderSentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff7a756fb4ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# Import flair pre-trained sentiment model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mflair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vaderSentiment'"
     ]
    }
   ],
   "source": [
    "# Initial Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Import flair pre-trained sentiment model\n",
    "from flair.models import TextClassifier\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "# Import flair Sentence to process input text\n",
    "from flair.data import Sentence\n",
    "import regex as re\n",
    "from sentiment_functions import clean_text, score_flair\n",
    "import datetime\n",
    "# BDay is business day, not birthday...\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5b313a-56e5-4722-b553-2cde648e92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many days would you like to retrieve twitter data for? 5\n",
      "What hashtag would you like to retrieve data for? $TSLA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-01-12 05:00:00+00:00', '2022-01-13 05:00:00+00:00',\n",
       "               '2022-01-14 05:00:00+00:00', '2022-01-15 05:00:00+00:00',\n",
       "               '2022-01-16 05:00:00+00:00', '2022-01-17 05:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-12T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-13T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-13T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-14T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-14T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-15T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-15T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-16T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-16T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2022-01-17T05:00:00+00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>conversation_id_str</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>...</th>\n",
       "      <th>possibly_sensitive_editable</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>source</th>\n",
       "      <th>supplemental_language</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1482146142339178499</th>\n",
       "      <td>None</td>\n",
       "      <td>1482146142339178499</td>\n",
       "      <td>1482146142339178499</td>\n",
       "      <td>None</td>\n",
       "      <td>Sat Jan 15 00:22:31 +0000 2022</td>\n",
       "      <td>[0, 214]</td>\n",
       "      <td>{'hashtags': [{'text': 'wallstreetbets', 'indi...</td>\n",
       "      <td>{'media': [{'id': 1482146140653072387, 'id_str...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"https://ifttt.com\" rel=\"nofollow\"&gt;IFT...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1422573397079375877</td>\n",
       "      <td>1422573397079375877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481783730788352001</th>\n",
       "      <td>None</td>\n",
       "      <td>1481783730788352001</td>\n",
       "      <td>1481783730788352001</td>\n",
       "      <td>None</td>\n",
       "      <td>Fri Jan 14 00:22:26 +0000 2022</td>\n",
       "      <td>[0, 212]</td>\n",
       "      <td>{'hashtags': [{'text': 'wallstreetbets', 'indi...</td>\n",
       "      <td>{'media': [{'id': 1481783728095510533, 'id_str...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"https://ifttt.com\" rel=\"nofollow\"&gt;IFT...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1422573397079375877</td>\n",
       "      <td>1422573397079375877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481421406487420934</th>\n",
       "      <td>None</td>\n",
       "      <td>1481421406487420934</td>\n",
       "      <td>1481421406487420934</td>\n",
       "      <td>None</td>\n",
       "      <td>Thu Jan 13 00:22:41 +0000 2022</td>\n",
       "      <td>[0, 210]</td>\n",
       "      <td>{'hashtags': [{'text': 'wallstreetbets', 'indi...</td>\n",
       "      <td>{'media': [{'id': 1481421404000165888, 'id_str...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"https://ifttt.com\" rel=\"nofollow\"&gt;IFT...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1422573397079375877</td>\n",
       "      <td>1422573397079375877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481277539410710533</th>\n",
       "      <td>None</td>\n",
       "      <td>1481277539410710533</td>\n",
       "      <td>1481277539410710533</td>\n",
       "      <td>None</td>\n",
       "      <td>Wed Jan 12 14:51:00 +0000 2022</td>\n",
       "      <td>[0, 276]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [{'text': 'qqq', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1286447494222745600</td>\n",
       "      <td>1286447494222745600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    contributors      conversation_id  conversation_id_str  \\\n",
       "1482146142339178499         None  1482146142339178499  1482146142339178499   \n",
       "1481783730788352001         None  1481783730788352001  1481783730788352001   \n",
       "1481421406487420934         None  1481421406487420934  1481421406487420934   \n",
       "1481277539410710533         None  1481277539410710533  1481277539410710533   \n",
       "\n",
       "                    coordinates                      created_at  \\\n",
       "1482146142339178499        None  Sat Jan 15 00:22:31 +0000 2022   \n",
       "1481783730788352001        None  Fri Jan 14 00:22:26 +0000 2022   \n",
       "1481421406487420934        None  Thu Jan 13 00:22:41 +0000 2022   \n",
       "1481277539410710533        None  Wed Jan 12 14:51:00 +0000 2022   \n",
       "\n",
       "                    display_text_range  \\\n",
       "1482146142339178499           [0, 214]   \n",
       "1481783730788352001           [0, 212]   \n",
       "1481421406487420934           [0, 210]   \n",
       "1481277539410710533           [0, 276]   \n",
       "\n",
       "                                                              entities  \\\n",
       "1482146142339178499  {'hashtags': [{'text': 'wallstreetbets', 'indi...   \n",
       "1481783730788352001  {'hashtags': [{'text': 'wallstreetbets', 'indi...   \n",
       "1481421406487420934  {'hashtags': [{'text': 'wallstreetbets', 'indi...   \n",
       "1481277539410710533  {'hashtags': [], 'symbols': [{'text': 'qqq', '...   \n",
       "\n",
       "                                                     extended_entities  \\\n",
       "1482146142339178499  {'media': [{'id': 1482146140653072387, 'id_str...   \n",
       "1481783730788352001  {'media': [{'id': 1481783728095510533, 'id_str...   \n",
       "1481421406487420934  {'media': [{'id': 1481421404000165888, 'id_str...   \n",
       "1481277539410710533                                                NaN   \n",
       "\n",
       "                    favorite_count favorited  ... possibly_sensitive_editable  \\\n",
       "1482146142339178499              0     False  ...                        True   \n",
       "1481783730788352001              0     False  ...                        True   \n",
       "1481421406487420934              1     False  ...                        True   \n",
       "1481277539410710533              0     False  ...                         NaN   \n",
       "\n",
       "                    quote_count reply_count retweet_count retweeted  \\\n",
       "1482146142339178499           0           0             0     False   \n",
       "1481783730788352001           0           0             0     False   \n",
       "1481421406487420934           0           0             2     False   \n",
       "1481277539410710533           0           0             0     False   \n",
       "\n",
       "                                                                source  \\\n",
       "1482146142339178499  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
       "1481783730788352001  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
       "1481421406487420934  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
       "1481277539410710533  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                    supplemental_language truncated              user_id  \\\n",
       "1482146142339178499                  None     False  1422573397079375877   \n",
       "1481783730788352001                  None     False  1422573397079375877   \n",
       "1481421406487420934                  None     False  1422573397079375877   \n",
       "1481277539410710533                  None     False  1286447494222745600   \n",
       "\n",
       "                             user_id_str  \n",
       "1482146142339178499  1422573397079375877  \n",
       "1481783730788352001  1422573397079375877  \n",
       "1481421406487420934  1422573397079375877  \n",
       "1481277539410710533  1286447494222745600  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking user input for number of days to retrieve data for, then creating the date range to iterate through for the API call\n",
    "\n",
    "\n",
    "def getTwitterData():\n",
    "        \n",
    "    tweets_df = pd.DataFrame()\n",
    "    numDays = int(input('How many days would you like to retrieve twitter data for?'))\n",
    "    hashtag = input('What hashtag would you like to retrieve data for?')\n",
    "    \n",
    "    today = datetime.datetime.today()\n",
    "    start = today - pd.Timedelta(days = numDays)\n",
    "    \n",
    "    \n",
    "\n",
    "    #Since we are retrieving data we want to correlate with markets, we are using 'bdate_range' to only return business days                \n",
    "    date_range = pd.bdate_range(start=start, end=today, freq=\"D\", tz='UTC') + pd.Timedelta(hours=5)\n",
    "    display(date_range)\n",
    "    \n",
    "    #Iterating through the date_range with an API call for each day to maximize data returned \n",
    "    # @TODO -- use function to limit API calls to not exceed limits\n",
    "    for i in range(0, len(date_range) -1, 1):\n",
    "    \n",
    "        start_date = date_range[i]\n",
    "        end_date = date_range[i+1] \n",
    "    \n",
    "    \n",
    "        start_date = pd.Timestamp.isoformat(start_date)\n",
    "        end_date = pd.Timestamp.isoformat(end_date)\n",
    "    \n",
    "    \n",
    "# Making the API call to retrieve tweets \n",
    "\n",
    "        source = \"https://twitter32.p.rapidapi.com/getSearch\"\n",
    "\n",
    "# These parameters need to be set before running API call... could in the future receive inputs from user\n",
    "## TODO -- if input is received, datetime will need to be formatted correctly for API call\n",
    "\n",
    "        hashtag = hashtag\n",
    "\n",
    "        querystring = {\"hashtag\": hashtag, \"start_date\": start_date,\"end_date\": end_date,\"lang\":\"en\"}\n",
    "        headers = {\n",
    "        'x-rapidapi-host': \"twitter32.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': \"49e5cedc9fmsh6a2df83dacfc4c1p1c3469jsn3edb2e8cb9df\"\n",
    "        }\n",
    "   \n",
    "        \n",
    "        response = requests.get(source, headers=headers, params=querystring).json()\n",
    "        df = pd.DataFrame(response['data']['tweets']).T\n",
    "        tweets_df = pd.concat([df, tweets_df])\n",
    "        display(start_date, end_date)\n",
    "    \n",
    "    return tweets_df\n",
    "\n",
    "tweets_df = getTwitterData()\n",
    "display(tweets_df)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef21a5-0a2d-4734-9b24-11cb7b36e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def getTodayTweets(current_df_path)\n",
    "    \n",
    "    todaysTweets_df = pd.DataFrame()\n",
    "    \n",
    "    current_df_path = Path('./twitter_flair.csv'\n",
    "    currentTweets_df = pd.read_csv(current_df_path, parse_dates = True, infer_datetime_format=True, index_col='Date')\n",
    "    hashtag = input('Please input desired hashtag to confirm')\n",
    "    \n",
    "    end_date = datetime.datetime.today()\n",
    "    start_date = today - pd.Timedelta(days=1)\n",
    "    \n",
    "    \n",
    "    #Iterating through the date_range with an API call for each day to maximize data returned \n",
    "    # @TODO -- use function to limit API calls to not exceed limit\n",
    "    \n",
    "    start_date = pd.Timestamp.isoformat(start_date)\n",
    "    end_date = pd.Timestamp.isoformat(end_date)\n",
    "    \n",
    "    \n",
    "    # Making the API call to retrieve tweets \n",
    "\n",
    "    source = \"https://twitter32.p.rapidapi.com/getSearch\"\n",
    "\n",
    "    # These parameters need to be set before running API call... could in the future receive inputs from user\n",
    "    ## TODO -- if input is received, datetime will need to be formatted correctly for API call\n",
    "\n",
    "    hashtag = hashtag\n",
    "    querystring = {\"hashtag\": hashtag, \"start_date\": start_date,\"end_date\": end_date,\"lang\":\"en\"}\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"twitter32.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': \"49e5cedc9fmsh6a2df83dacfc4c1p1c3469jsn3edb2e8cb9df\"\n",
    "        }\n",
    "   \n",
    "        \n",
    "    response = requests.get(source, headers=headers, params=querystring).json()\n",
    "    todaysTweets_df = pd.DataFrame(response['data']['tweets']).T\n",
    "    updatedTweets_df = pd.concat([todays_Tweets_df, currentTweets])\n",
    "    display(start_date, end_date)\n",
    "                           \n",
    "    \n",
    "    return updatedTweets_df\n",
    "\n",
    "updatedTweets_df = getTwitterData('./twitter_flair.csv')\n",
    "display(tweets_df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d23baae-4280-4d37-a268-10593a77daf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-15 00:22:31+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:22:26+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13 00:22:41+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12 14:51:00+00:00</th>\n",
       "      <td>advise needed! - I mistakenly bought an option...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   full_text  \\\n",
       "Date                                                                           \n",
       "2022-01-15 00:22:31+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "2022-01-14 00:22:26+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "2022-01-13 00:22:41+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "2022-01-12 14:51:00+00:00  advise needed! - I mistakenly bought an option...   \n",
       "\n",
       "                          retweet_count  \n",
       "Date                                     \n",
       "2022-01-15 00:22:31+00:00             0  \n",
       "2022-01-14 00:22:26+00:00             0  \n",
       "2022-01-13 00:22:41+00:00             2  \n",
       "2022-01-12 14:51:00+00:00             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing and formatting the dataframe to index by date created and isolating the 'full_text' and 'retweet_count' columns for sentiment analysis\n",
    "df_filtered = tweets_df.loc[:,[\"created_at\",\"full_text\", 'retweet_count']]\n",
    "df_filtered.index = pd.to_datetime(df_filtered['created_at'], utc=True)\n",
    "df_filtered.index.name = 'Date'\n",
    "df_filtered.drop(columns='created_at', inplace=True)\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec0834d-6731-4f74-ac08-6b3c2ad1e26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-12 14:51:00+00:00</th>\n",
       "      <td>advise needed I mistakenly bought an option wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13 00:22:41+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:22:26+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-15 00:22:31+00:00</th>\n",
       "      <td>Following were the Top 5 tickers mentioned on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   full_text  \\\n",
       "Date                                                                           \n",
       "2022-01-12 14:51:00+00:00  advise needed I mistakenly bought an option wi...   \n",
       "2022-01-13 00:22:41+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "2022-01-14 00:22:26+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "2022-01-15 00:22:31+00:00  Following were the Top 5 tickers mentioned on ...   \n",
       "\n",
       "                          retweet_count  \n",
       "Date                                     \n",
       "2022-01-12 14:51:00+00:00             0  \n",
       "2022-01-13 00:22:41+00:00             2  \n",
       "2022-01-14 00:22:26+00:00             0  \n",
       "2022-01-15 00:22:31+00:00             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to clean up our tweets so they can be analyzed in string format\n",
    "# Applying our imported 'clean_text' function to text column of our dataframe\n",
    "df_filtered[\"full_text\"] = df_filtered[\"full_text\"].apply(clean_text)\n",
    "df_filtered = df_filtered.sort_index()\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582163af-e88a-4475-986f-1c220d1c8b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            4\n",
       "unique           1\n",
       "top       NEGATIVE\n",
       "freq             4\n",
       "Name: pred_flair, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get sentiment score for each review\n",
    "df_filtered['scores_flair'] = df_filtered['full_text'].apply(lambda s: score_flair(s)[0])\n",
    "# Predict sentiment label for each review\n",
    "df_filtered['pred_flair'] = df_filtered['full_text'].apply(lambda s: score_flair(s)[1])\n",
    "# Check the distribution of the score\n",
    "df_filtered['scores_flair'].describe()\n",
    "# Change the label of flair prediction to 0 if negative and 1 if positive\n",
    "#mapping = {'NEGATIVE': 0, 'POSITIVE': 1}\n",
    "#df_filtered['pred_flair_numerical'] = df_filtered['pred_flair'].map(mapping)\n",
    "df_filtered['pred_flair'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef997c8-e7eb-4a27-839d-bc3d0d921d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEGATIVE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-12 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-15 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NEGATIVE\n",
       "Date                               \n",
       "2022-01-12 00:00:00+00:00       1.0\n",
       "2022-01-13 00:00:00+00:00       1.0\n",
       "2022-01-14 00:00:00+00:00       1.0\n",
       "2022-01-15 00:00:00+00:00       1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Converting the categorical variable columns into numerical with get_dummies\n",
    "df_dummies = pd.get_dummies(df_filtered['pred_flair'])\n",
    "# Dropping the row if the scores_flair confidence level is below 0.75\n",
    "df_filtered.drop(df_filtered[df_filtered.scores_flair < 0.75].index, inplace=True)\n",
    "# Creating the 'df_signals' dataframe that we will use to append to our primary dataset, using only the columns with relevant numerical values, resampled by day\n",
    "df_signals = df_filtered.drop(columns=['scores_flair', 'pred_flair'])\n",
    "final_df = pd.concat([df_signals, df_dummies]).resample('D').sum()\n",
    "display(final_df)  \n",
    "#final_df.to_csv('twitter_flair.csv')\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1b639-ed2a-45b2-abf2-375ac0170b4a",
   "metadata": {},
   "source": [
    "### After pulling tweet data, performing sentiment analysis using flair and then filtered and resampling the dataframe, we return a dataframe with datetime indices with two columns -- flair_negative, which is the sum of all negative tweets for the day, and flair_positive, which is the sum of all positive tweets for the day -- at some point we could think about factoring in number of retweets or something along those lines to weigh the tweets by their impact, but the results from the API call already filter by this metric, so could be superfluous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d090eb5-2eb7-43b6-a4e4-31782fb1a0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa275b6-b3ff-43e9-8879-8807e7ce7a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db42885-eb6f-4e96-a2a4-e27b62ce4976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bbdb6d-2287-48cd-9215-e5984b256728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2-dev",
   "language": "python",
   "name": "project2-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
